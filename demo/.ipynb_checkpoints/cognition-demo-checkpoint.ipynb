{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from osgeo import gdal\n",
    "import boto3\n",
    "import json\n",
    "from datetime import datetime\n",
    "cognition_path = '../'\n",
    "\n",
    "if cognition_path not in sys.path:\n",
    "    sys.path.append(cognition_path)\n",
    "\n",
    "from cognition.pygdal.raster import RasterDataset\n",
    "from cognition.grid import GridFactory\n",
    "\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Create the grid\n",
    "For this demo we will be ingesting 5 Landsat 8 (ARD) scenes of Southern California acquired from USGS Earth Explorer.  The images were preprocessed by combining the R/G/B/NIR bands into 4-band composites.  All input data can be found in the `cognition/testdata` folder.  We will make the grid based on the combined extent of the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the combined extent by passing a VRT into RasterDataset\n",
    "bucket = 'cognition-testdata'\n",
    "key = 'cognition-poc/'\n",
    "\n",
    "files = []\n",
    "test = s3.Bucket(bucket)\n",
    "for item in test.objects.filter(Prefix=key):\n",
    "    if item.key.endswith('.tif'):\n",
    "        files.append(os.path.join('/vsis3/', bucket, item.key))\n",
    "\n",
    "vrt = RasterDataset(gdal.BuildVRT('/vsimem/landsat_merged.tif', files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create grid with configuration file\n",
    "The first way of creating a grid is through a configuration .json file.  The `GridFactory` object supports reading python dicts by passing the dict to the constructor.  It is expected that cognition will provide command line utilities which read the configuration from a `config.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = {'epsg': vrt.epsg,\n",
    "          'xsize': (vrt.shape[0]/4)*vrt.xres, #Size of each grid cell expressed in srs linear unit\n",
    "          'ysize': (vrt.shape[1]/4)*vrt.yres,\n",
    "          'extent': vrt.extent,\n",
    "          'root': 'cognition-poc'\n",
    "         }\n",
    "\n",
    "#Build grid with configuration\n",
    "grid_factory = GridFactory(config)\n",
    "grid = grid_factory.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Creating grid with dictionary indexing\n",
    "The `GridFactory` object inherits from python's `dict` object and behaves just like any other `dict`.  The dict interface allows the configuration class to be easily extended.  `GridFactory` has a modified `update` method which lets the user set specific parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_factory = GridFactory()\n",
    "for k,v in config.items():\n",
    "    grid_factory.update({k:v})\n",
    "grid = grid_factory.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Dumps and loads\n",
    "The `GridFactory` object has a standard dumps/loads protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epsg': 4326, 'xsize': 1.108917105081349, 'ysize': 0.9748070475469244, 'extent': [-121.8756733615818, -117.4400049412564, 33.036392850208344, 36.93562104039604], 'root': 'cognition-poc'}\n"
     ]
    }
   ],
   "source": [
    "grid_factory = GridFactory()\n",
    "grid_factory.loads(config) #Load configuration from dictionary\n",
    "print(grid_factory.dumps()) #Dump configuration to dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Upload grid to S3\n",
    "Once the grid has been created from a configuration it may be uploaded to S3.  The root directory of the grid is determined by the `root` parameter in the grid configuration.  Upon upload, the grid is converted to a flat file structure of format `s3://{root}/{grid_geohash}/` and will create subfolders equal to the number of grid cells.  Each grid cell is spatially indexed using the geohash of it's centroid (WGS84) which doubles as a unique identifier for the grid.  Each grid cell contains a metadata file `s3://{root}/{grid_geohash}/metadata.json` containing basic information about the grid cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9mc9pm2edg3s/metadata.json\n",
      "9mcwxqbd6b9d/metadata.json\n",
      "9mf90t25d7qh/metadata.json\n",
      "9mfw8wb462w4/metadata.json\n",
      "9mg31tred56s/metadata.json\n",
      "9mgq9wzd60dd/metadata.json\n",
      "9mu14vr59erh/metadata.json\n",
      "9muchjqe977s/metadata.json\n",
      "9mundyz438x4/metadata.json\n",
      "9muysnyd32ed/metadata.json\n",
      "9q1sr228fvc9/metadata.json\n",
      "9q39z38xdfcx/metadata.json\n",
      "9q3xr70w6b1w/metadata.json\n",
      "9q4s2820fmy1/metadata.json\n",
      "9q5k38r8fjf9/metadata.json\n",
      "9q69b98pd6yp/metadata.json\n",
      "9q6x2e0n62nn/metadata.json\n",
      "9q73c9xxd4fx/metadata.json\n",
      "9q7r3epw604w/metadata.json\n",
      "9qhh6br0ctz1/metadata.json\n",
      "9qhuk0q8cmg9/metadata.json\n",
      "9qk1fcxp9dzp/metadata.json\n",
      "9qkcu1wx96gx/metadata.json\n",
      "9qkp6gpn38pn/metadata.json\n",
      "9qkzk5nw325w/metadata.json\n"
     ]
    }
   ],
   "source": [
    "#Confirming the deploy\n",
    "bucket = s3.Bucket(grid_factory['root'])\n",
    "for obj in bucket.objects.all():\n",
    "    if 'metadata' in obj.key:\n",
    "        print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"bounds\": [\n",
      "    -121.8756733615818,\n",
      "    -120.76675625650046,\n",
      "    32.06158580266142,\n",
      "    33.036392850208344\n",
      "  ],\n",
      "  \"centroid\": [\n",
      "    -121.32121480904111,\n",
      "    32.54898932643488\n",
      "  ],\n",
      "  \"geometry\": {\n",
      "    \"type\": \"Polygon\",\n",
      "    \"coordinates\": [\n",
      "      [\n",
      "        [\n",
      "          -121.8756733615818,\n",
      "          33.036392850208344\n",
      "        ],\n",
      "        [\n",
      "          -120.76675625650046,\n",
      "          33.036392850208344\n",
      "        ],\n",
      "        [\n",
      "          -120.76675625650046,\n",
      "          32.06158580266142\n",
      "        ],\n",
      "        [\n",
      "          -121.8756733615818,\n",
      "          32.06158580266142\n",
      "        ],\n",
      "        [\n",
      "          -121.8756733615818,\n",
      "          33.036392850208344\n",
      "        ]\n",
      "      ]\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Looking at one of the metadata.json files\n",
    "obj = s3.Object(grid_factory['root'], '9mc9pm2edg3s/metadata.json')\n",
    "test = obj.get()['Body'].read().decode('utf-8')\n",
    "print(json.dumps(json.loads(test), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build Spatial Index\n",
    "Now that the grid has been built, we will open it and generate a spatial index.  Currently only supports in-memory indices which must be rebuit every time the grid is opened.  Fully anticipate supporting saving indices to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognition.grid.grid import Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the grid with the root\n",
    "demo_grid = Grid(grid_factory['root'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the index\n",
    "demo_grid.build_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Spatial Indices\n",
    "Geohashes serialize space, allowing for basic spatial operations to be performed very quickly.  A bounding box query, for example, is a simple prefix lookup by the following procedure:\n",
    "1. Convert each corner of bounding box to geohashes.\n",
    "2. Find the longest shared prefix among the corner hashes.\n",
    "3. Any geohash with the same prefix is contained within the bounding box (see `cognition.query.geohash.bbox_query`)\n",
    "\n",
    "Cognition provides built-in access to a number of in-memory indices used to perform prefix searches (and thus bounding box queries).  When no input is passed to the `Grid.build_index` constructor, Cognition defaults to the `builtin` spatial index which is simple a list comprehension of form:\n",
    "\n",
    "```python\n",
    "[x for x in geohashes if x.startswith(bbox_prefix)]\n",
    "```\n",
    "\n",
    "The other spatial indices included in Cognition are various types of [Trie](https://en.wikipedia.org/wiki/Trie) and [DAWG](https://en.wikipedia.org/wiki/Deterministic_acyclic_finite_state_automaton) indices.  See `cognition.index.indices.get_tree` for the available spatial indices which may be generated as follows:\n",
    "\n",
    "```python\n",
    "demo_grid = Grid(grid_factory['root'])\n",
    "demo_grid.build_index(index_name=\"trie\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Spatial Index Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [geohash-playground repository](https://github.com/geospatial-jeff/geohash-playground) contains a benchmarking tool for assessing the load and query speed of the various spatial indices supported by Cognition.  This allows the user to determine which spatial index is most optimal for their grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ingest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 File Configuration\n",
    "We will define a function used to generate a configuration json from the LS8 filenames.  The various parts of the configuration are used to build out the S3 flat file structure for each image in the form of `s3://{root}/{grid_geohash}/{sensor}/{date}/{image_name.tif}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://landsat.usgs.gov/ard\n",
    "example_name = 'LC08_CU_002010_20180610_20180912_C01_V01_RGBNIR.tif'\n",
    "\n",
    "def ls8_config(filename):\n",
    "    filename = os.path.splitext(filename)[0]\n",
    "    parts = filename.split('_')\n",
    "    return {'sensor': 'Landsat8',\n",
    "            'date': datetime.strptime(parts[3],'%Y%m%d'), #Should be datetime object\n",
    "            'product': parts[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sensor': 'Landsat8', 'date': datetime.datetime(2018, 6, 10, 0, 0), 'product': 'RGBNIR'}\n",
      "{'sensor': 'Landsat8', 'date': datetime.datetime(2018, 8, 6, 0, 0), 'product': 'RGBNIR'}\n",
      "{'sensor': 'Landsat8', 'date': datetime.datetime(2018, 8, 15, 0, 0), 'product': 'RGBNIR'}\n",
      "{'sensor': 'Landsat8', 'date': datetime.datetime(2018, 8, 22, 0, 0), 'product': 'RGBNIR'}\n",
      "{'sensor': 'Landsat8', 'date': datetime.datetime(2018, 2, 4, 0, 0), 'product': 'RGBNIR'}\n"
     ]
    }
   ],
   "source": [
    "#Generate configurations\n",
    "file_names = [os.path.split(x)[-1] for x in files]\n",
    "configs = [ls8_config(x) for x in file_names]\n",
    "for item in configs:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 COG Profile\n",
    "A COG profile defines the specifications used to generate the COG (ex. tilesize, compression etc.).  Cognition provides both a default COG profile and an extendable base class for generating custom COG profiles.  The default COG profile can be found at `cognition.cog.profiles.DefaultCOG` and is passed as the default COG profile to `cognition.pygdal.raster.RasterDataset.Cogify`.\n",
    "\n",
    "Let's pretend we want to generate a COG Profile which dynamically changes tile size based on the image's spatial resolution and adjusts compression based on radiometric resolution.  We can do so by generating a new COG profile very similar to `DefaultCOG`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognition.cog.profiles import COGBase\n",
    "\n",
    "class MyCustomCog(COGBase):\n",
    "    \n",
    "    def __init__(self, ds):\n",
    "        COGBase.__init__(self, ds)\n",
    "        self.set_tilesize()\n",
    "    \n",
    "    def set_tilesize(self):\n",
    "        if self.ds.xres > 15 and self.ds.yres > 15:\n",
    "            self.blocksize = 256\n",
    "        else:\n",
    "            self.blocksize = 512\n",
    "    \n",
    "    def set_compression(self):\n",
    "        if self.ds.bitdepth is 'Byte':\n",
    "            self.compression = 'JPEG'\n",
    "        else:\n",
    "            self.compression = 'DEFLATE'\n",
    "            self.zlevel = '9'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our own COG profile we can use when generating COG's on ingest which dynamically responds to spatial resolution and bit depth!  Please note that, as of now, any extension to the base class must set both `compression` and `blocksize`, as these are not defined in `COGBase`.  Also note that `COGBase`, by default defines several variables such as `BIGTIFF=IF_SAFER` and `NUM_THREADS=ALL_CPUS` which are generally acceptable in most situations but may be overridden using the appropriate setter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Ingest data with configuration file\n",
    "The images will now be converted to COGs (if not already) and uploaded.\n",
    "\n",
    "**Following cell is commented.  Don't run the next cell, data is already ingested and it takes a while**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[demo_grid.ingest(x,y) for (x,y) in zip(files, configs)]\n",
    "\n",
    "#If we wanted to use our custom COG profile:\n",
    "#[demo_grid.ingest(x,y,profile=MyCustomCog) for (x,y) in zip(files,configs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Query\n",
    "Lets now query the data we have ingested.  In order to calculate NDVI, we need both the Red (band 1) and NIR (band4) bands.  We must also pass a bounding box in the form of `[xmin, xmax, ymin, ymax]` and a datetime object indicating the day to search.  The query will generate a list of `cognition.pygdal.raster.BandStack` objects, each containing the Red and NIR bands of COG blocks within the extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blocks: 143\n"
     ]
    }
   ],
   "source": [
    "input_file = RasterDataset(gdal.Open(files[0]))\n",
    "extent = input_file.extent\n",
    "date = datetime(2018, 6, 10)\n",
    "\n",
    "query_result = demo_grid.query(extent=extent,\n",
    "                               temporal=date,\n",
    "                               sensor='Landsat8',\n",
    "                               bands=[1,4])\n",
    "print(\"Number of blocks: {}\".format(len(query_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Calculate NDVI\n",
    "We can use the `cognition.pygdal.raster.RasterDataset` methods to embed a pixel function into each COG block. \n",
    "\n",
    "\n",
    "**Note: Currently having trouble getting pixel functions to work in conjunction with block reads.  For the sake of demonstration we will save the block locally and then calculate NDVI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_func = '../pixel_functions/ndvi.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab one block and save locally\n",
    "test_block = query_result[23]\n",
    "test_block.Save('../outputs/output.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embed the function\n",
    "embedded = RasterDataset(gdal.Open('../outputs/output.tif')).EmbedFunction(pixel_func, [1,2], out_depth='Float32')\n",
    "embedded.Save('../outputs/ndvi.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Final Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 `pygdal` Configuration\n",
    "Pygdal has an internal logging system located at `cognition.pygdal.config` which provides logging and tempfile handling for the rest of the library.  The user can edit configuration options using an interface similar to GDAL's.  Note that because Pygdal is simply a wrapper of GDAL, it will honor any calls to `gdal.SetConfigOption`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cognition.pygdal as pg\n",
    "\n",
    "pg.SetConfigOption('LOGGING', \"TRUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When logging is enabled, pygdal will log all operations decorated with the `@pygdal_config.log_operation` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"id\": \"0b709bf71a4a46fa8a8dad3d990d06d7\",\n",
      "      \"fname\": \"/vsimem/bandstack/b0403b3811f54c698db4350c0c5f5007.vrt\"\n",
      "    }\n",
      "  ],\n",
      "  \"intermediates\": [\n",
      "    {\n",
      "      \"parent\": \"0b709bf71a4a46fa8a8dad3d990d06d7\",\n",
      "      \"id\": \"68d382a1bdb94c90a222536821fc7be8\",\n",
      "      \"operation\": \"Reproject\",\n",
      "      \"args\": {\n",
      "        \"out_srs\": 3857\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"outputs\": [\n",
      "    {\n",
      "      \"parent\": \"68d382a1bdb94c90a222536821fc7be8\",\n",
      "      \"id\": \"a6b1e981245e4b31b15978f758dc8c36\",\n",
      "      \"operation\": \"Save\",\n",
      "      \"args\": {\n",
      "        \"out_path\": \"/vsimem/test_logs.tif\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "proj_ds = test_block.Reproject(3857)\n",
    "proj_ds.Save('/vsimem/test_logs.tif')\n",
    "pg.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user may also toggle the temporary save directory between `/vsimem/` and a specified path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.SetConfigOption('TEMP_SAVE', '../tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../tmp/Reproject/1a283794f2ee4cabb58ad48e37afd867.vrt\n"
     ]
    }
   ],
   "source": [
    "proj_block = test_block.Reproject(3857)\n",
    "\n",
    "print(proj_block.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove temporary files\n",
    "pg.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
