import math
import geohash
import os
import pyproj
from shapely.geometry import shape
from shapely.ops import transform
import boto3
import json
import multiprocessing
from functools import partial
from osgeo import gdal

from cognition.index.indices import get_tree
from cognition.query.geohash import bbox_query
from cognition.pygdal.raster import RasterDataset, BandStack
from cognition.cog.cog import COG

s3 = boto3.resource('s3')

class ConfigurationError(BaseException):
    pass

class GridFactory(dict):

    """Factory object for creating grids, each made up of many cells"""

    accepted = ['epsg', 'xsize', 'ysize', 'extent', 'root']

    def __init__(self, config=None):
        """Super so we just inherit dict methods, not attributes"""
        super(GridFactory, self).__init__()
        if config:
            self.update(config)

    def loads(self, d):
        """Load from configuration json"""
        return self.update(d)

    def dumps(self):
        """Dump configuration to dictionary"""
        return dict(zip(list(self.keys()), list(self.values())))

    def update(self, d):
        """Overwriting base update method to only add accepted keys"""
        error_list = []
        for k,v in d.items():
            if k in self.accepted:
                self[k] = v
            else:
                error_list.append(k)
        if len(error_list) > 0:
            raise AttributeError("The following input parameters are invalid: {}".format(error_list))



    def create(self):
        """Method to generate a Grid based on the input configuration"""
        def wrapper():
            width = self['extent'][1] - self['extent'][0]
            height = self['extent'][3] - self['extent'][2]
            rows = int(math.ceil(width/self['xsize']))
            cols = int(math.ceil(height/self['ysize']))
            for col in range(cols):
                for row in range(rows):
                    xmin = self['extent'][0] + (col * self['xsize'])
                    ymax = self['extent'][3] - (row * self['ysize'])
                    xmax = xmin + self['xsize']
                    ymin = ymax - self['ysize']
                    yield Cell((xmin, xmax, ymin, ymax),self.dumps())
        return _Grid(wrapper())



class Cell(object):

    """Cell base class.  Represents one cell of a grid."""

    @staticmethod
    def _centroid(geo_interface, epsg):
        """Method to generate WGS84 centroid"""
        centroid = shape(geo_interface).centroid
        if epsg != 4326:
            project = partial(pyproj.transform, pyproj.Proj(init='epsg:{}'.format(epsg)), pyproj.Proj(init='epsg:4326'))
            cent4326 = transform(project, centroid)
            return [cent4326.x, cent4326.y]
        return [centroid.x, centroid.y]

    def __init__(self, bounds, settings, precision=12):
        self.settings = settings #This contains the output of GridFactory.dumps
        self.bounds = bounds
        self.centroid = self._centroid(self.__geo_interface__, self.settings['epsg'])
        self.geohash = geohash.encode(self.centroid[1], self.centroid[0], precision)

    @property
    def __geo_interface__(self):

        """Defines a geo interface protocol (see https://gist.github.com/sgillies/2217756)"""
        return {'type': 'Polygon', 'coordinates': ([[[self.bounds[0], self.bounds[3]],
                                                     [self.bounds[1], self.bounds[3]],
                                                     [self.bounds[1], self.bounds[2]],
                                                     [self.bounds[0], self.bounds[2]],
                                                     [self.bounds[0], self.bounds[3]]]])}

    def upload(self):
        "Upload a grid cell to s3://{root}{geohash}/{metadata.json}"
        data = {'bounds': self.bounds,
                'centroid': self.centroid,
                'geometry': self.__geo_interface__}
        try:
            object = s3.Object(self.settings['root'], os.path.join(self.geohash, 'metadata.json'))
            object.put(Body=json.dumps(data))
        except KeyError:
            raise ConfigurationError("User is attempting to deploy grid to s3 but root bucket is not specified")

class _Grid(object):

    """Private class generated by GridFactory"""

    def __init__(self, cells):
        self.cells = cells

    def deploy(self, multi=False):
        if multi:
            m = multiprocessing.Pool(multiprocessing.cpu_count()-1)
            m.map(_uploadcell, self.cells)
            return
        for cell in self.cells:
            cell.upload()

    def __len__(self):
        return len(list(self.cells))

class Grid(object):

    """
    A Grid represents a grid, or collection of cells, deployed by Cognition.  The Grid object is opened using the root
    name (bucket) of the architecture.
    """

    @staticmethod
    def get_geohashes(root):
        """Method to retrieve the geohash of each grid cell using boto3"""
        bucket = s3.Bucket(root)
        return list(set([os.path.split(x.key)[0].split('/')[0] for x in bucket.objects.all()]))

    def __init__(self, root):
        self.root = root
        self.geohashes = self.get_geohashes(root)
        self._index = None
        self.bucket = s3.Bucket(self.root)

    @property
    def index(self):
        return self._index

    @index.setter
    def index(self, value):
        self._index = value

    def build_index(self, index_name=None):
        """Method to build a spatial index, required for ingesting and querying"""
        if not index_name:
            self.index = get_tree(self.geohashes, "builtin")
        else:
            self.index = get_tree(self.geohashes, index_name)

    def ingest(self, img_path, config, multi=False, cog_profile=None, split_bands=True):
        """Method to ingest an image into the architecture"""
        if not self.index:
            # Build the default index is index is not set
            self.build_index()
        ds = RasterDataset(gdal.Open(img_path))
        res = bbox_query(ds.extent, self.index, 12)
        fname = os.path.split(img_path)[-1]

        #Setting up a package of raster data we will iterate over
        if split_bands:
            package = ds.SplitBands()
        else:
            package = [ds]

        args = []
        #Figuring out all the operations we want to perform
        for geohash in res:
            meta = json.loads(s3.Object(self.root, os.path.join(geohash, 'metadata.json')).get()['Body'].read().decode('utf-8'))
            bounds = meta['bounds']
            for idx, asset in enumerate(package):
                if split_bands:
                    split = os.path.splitext(fname)
                    band_fname = split[0] + '_B{}'.format(idx+1) + split[1]
                    prefix = os.path.join(self.root, geohash, config['sensor'], config['date'].strftime('%Y-%m-%d'))
                    args.append(
                        {'grid_bounds': bounds,
                         'prefix': prefix,
                         'fname': band_fname,
                         'data': asset,
                         }
                        )
                else:
                    prefix = os.path.join(self.root, geohash, config['sensor'], config['date'].strftime('%Y-%m-%d'))
                    args.append({'grid_bounds': bounds,
                                 'prefix': prefix,
                                 'fname': fname,
                                 'data': asset})

        #Performing the operations
        for item in args:
            print("Processing {}".format(os.path.join(item['prefix'], item['fname'])))
            clip = item['data'].BboxClip(item['grid_bounds'])
            if cog_profile:
                cog = clip.Cogify(profile=cog_profile)
            else:
                cog = clip.Cogify()
            cog.Upload(item['prefix'], name=item['fname'])

    def query(self, extent, temporal, sensor, bands):
        res = bbox_query(extent, self.index, 12)

        band_stack = []
        # for i in bands:
        #     args['band'+str(i)] = []
        for hash in res:
            prefix = os.path.join(hash, sensor, temporal.strftime('%Y-%m-%d'))
            # First find all files that match the query within this grid (this will be handled by STAC in later versions)
            files = [os.path.join(self.root, x.key) for x in self.bucket.objects.filter(Prefix=prefix) if int(os.path.splitext(x.key)[0][-1]) in bands]
            if len(files) > 0:
                # Now find all of the offsets within the query extent
                # Open one COG as a sample (assuming other assets of same sensor are similar)
                ds = COG(gdal.Open('/vsis3/{}'.format(files[0])))
                offsets = list(ds.offsets(filter=extent))
                ds = None
                band_list = []
                for item in files:
                    blocks = COG(gdal.Open('/vsis3/{}'.format(item))).blocks(offsets=offsets)
                    band_list.append(blocks)
                band_zipped = zip(*band_list)
                for item in band_zipped:
                    band_stack.append(BandStack(item))
        return band_stack



def _uploadcell(cell):
    cell.upload()

def read_vsimem(fn):
    '''Retrieve XML string from /vsimem/*.vrt'''
    vsifile = gdal.VSIFOpenL(fn,'r')
    gdal.VSIFSeekL(vsifile, 0, 2)
    vsileng = gdal.VSIFTellL(vsifile)
    gdal.VSIFSeekL(vsifile, 0, 0)
    return gdal.VSIFReadL(1, vsileng, vsifile).decode('utf-8')